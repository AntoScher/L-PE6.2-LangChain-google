{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMYgk9P8yW4bLN8DyKfi6rH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AntoScher/L-PE6.2-LangChain-google/blob/main/%D0%A0%D0%956_3forGem1_5_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-auth==2.38.0\n",
        "!pip install -qU langchain-google-genai>=0.1.3 chromadb>=0.4.16 tiktoken>=0.7.0\n",
        "!pip install langchain>=0.2.0 langchain-core>=0.2.0 langchain-text-splitters langchain-community\n",
        "!pip show chromadb langchain langchain-community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lvP4JgRr5RO9",
        "outputId": "bcb3119d-f0c9-4958-f6c8-2b871388a995"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-auth==2.38.0 in /usr/local/lib/python3.11/dist-packages (2.38.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth==2.38.0) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth==2.38.0) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth==2.38.0) (4.9.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth==2.38.0) (0.6.1)\n",
            "Name: chromadb\n",
            "Version: 1.0.12\n",
            "Summary: Chroma.\n",
            "Home-page: https://github.com/chroma-core/chroma\n",
            "Author: \n",
            "Author-email: Jeff Huber <jeff@trychroma.com>, Anton Troynikov <anton@trychroma.com>\n",
            "License: \n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: bcrypt, build, fastapi, grpcio, httpx, importlib-resources, jsonschema, kubernetes, mmh3, numpy, onnxruntime, opentelemetry-api, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, opentelemetry-sdk, orjson, overrides, posthog, pydantic, pypika, pyyaml, rich, tenacity, tokenizers, tqdm, typer, typing-extensions, uvicorn\n",
            "Required-by: \n",
            "---\n",
            "Name: langchain\n",
            "Version: 0.3.25\n",
            "Summary: Building applications with LLMs through composability\n",
            "Home-page: \n",
            "Author: \n",
            "Author-email: \n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: langchain-core, langchain-text-splitters, langsmith, pydantic, PyYAML, requests, SQLAlchemy\n",
            "Required-by: langchain-community\n",
            "---\n",
            "Name: langchain-community\n",
            "Version: 0.3.24\n",
            "Summary: Community contributed LangChain integrations.\n",
            "Home-page: \n",
            "Author: \n",
            "Author-email: \n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: aiohttp, dataclasses-json, httpx-sse, langchain, langchain-core, langsmith, numpy, pydantic-settings, PyYAML, requests, SQLAlchemy, tenacity\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import chromadb\n",
        "from google.colab import userdata\n",
        "\n",
        "# LangChain компоненты\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
        "from langchain.vectorstores import Chroma  # Импорт из основного модуля LangChain\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "# Инициализация Chroma\n",
        "client = chromadb.Client()"
      ],
      "metadata": {
        "id": "666Lm6fm5YsU",
        "collapsed": true
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')\n"
      ],
      "metadata": {
        "id": "UvUTyq1C5cSk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Исходный текст\n",
        "text = '''Благодаря появлению LLM возникла новая профессия будущего.\n",
        "Это промпт-инженер, который наилучшим образом направляет LLM на правильный путь.\n",
        "Этот специалист должен обладать творческим мышлением и аналитическими способностями,\n",
        "и желательно знанием методов машинного обучения и NLP и навыками программирования'''\n",
        "\n",
        "# Разделение на чанки\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=250,\n",
        "    chunk_overlap=100,\n",
        "    separators=['.\\n']\n",
        ")\n",
        "splits = splitter.split_text(text)\n",
        "\n",
        "# Инициализация моделей\n",
        "model = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\", temperature=0.7)\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "\n",
        "# Создание векторного хранилища\n",
        "vectorstore = Chroma.from_texts(\n",
        "    texts=splits,\n",
        "    embedding=embeddings,\n",
        "    collection_name=\"my_rag_collection\",\n",
        "    client=client,\n",
        "    persist_directory=None\n",
        ")\n",
        "\n",
        "# Проверка\n",
        "test_embedding = embeddings.embed_query(\"test\")\n",
        "print(f\"Размерность эмбеддингов: {len(test_embedding)}\")  # Должно быть 768"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKZxIz1RpMf_",
        "outputId": "55c7b49f-d1a0-47d8-a818-afdc1437c55d",
        "collapsed": true
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размерность эмбеддингов: 768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def rag_query(question: str, k=2):\n",
        "    docs = vectorstore.similarity_search(question, k=k)  # Используем vectorstore\n",
        "    return \"\\n\\n\".join([f\"Документ {i+1}:\\n{doc.page_content}\" for i, doc in enumerate(docs)])\n",
        "\n",
        "prompt_template = \"\"\"\n",
        "Ты - эксперт по анализу текстов. Ответь на вопрос, используя только предоставленные документы:\n",
        "\n",
        "{context}\n",
        "\n",
        "Вопрос: {question}\n",
        "\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(prompt_template)\n",
        "chain = (\n",
        "    {\"context\": rag_query, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | model\n",
        "    | StrOutputParser()\n",
        ")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "bFMuodaSpPtl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Ответ 1:\")\n",
        "print(chain.invoke(\"Кто такой промпт-инженер?\"))\n",
        "\n",
        "print(\"\\nОтвет 2:\")\n",
        "print(chain.invoke(\"Какие навыки нужны промпт-инженеру?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cl63Uvx1pVye",
        "outputId": "c8c75d3e-d0c1-461b-b5c1-6c2973f73b9e",
        "collapsed": true
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ответ 1:\n",
            "Промпт-инженер — это специалист, который наилучшим образом направляет LLM на правильный путь.\n",
            "\n",
            "Ответ 2:\n",
            "Творческое мышление, аналитические способности, желательно знание методов машинного обучения и NLP, и навыки программирования.\n"
          ]
        }
      ]
    }
  ]
}